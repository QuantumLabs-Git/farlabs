"""
Far Mesh Coordinator HTTP API

FastAPI server exposing distributed inference endpoints.
"""

import logging
from contextlib import asynccontextmanager
from typing import AsyncIterator
from fastapi import FastAPI, HTTPException, Header
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import json

from coordinator import (
    FarMeshCoordinator,
    InferenceRequest,
    TokenResponse,
    FineTuningRequest,
    FineTuningStatus
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Global coordinator instance
coordinator: FarMeshCoordinator | None = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown logic"""
    global coordinator

    # Startup
    logger.info("Starting Far Mesh Coordinator Service")

    coordinator = FarMeshCoordinator(
        model_id="meta-llama/Llama-2-7b-chat-hf",  # Default model
        # DHT bootstrap will be configured via environment variables
    )

    await coordinator.initialize()
    logger.info("âœ“ Far Mesh Coordinator initialized and ready")

    yield

    # Shutdown
    logger.info("Shutting down Far Mesh Coordinator Service")
    if coordinator:
        await coordinator.shutdown()


# Create FastAPI app
app = FastAPI(
    title="Far Mesh Coordinator",
    description="Distributed inference API powered by Far Labs mesh network",
    version="0.1.0",
    lifespan=lifespan
)

# Add CORS middleware
import os
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "https://app.farlabs.ai").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "far-mesh-coordinator",
        "version": "0.1.0"
    }


@app.get("/mesh/status")
async def get_mesh_status():
    """Get Far Mesh network status"""
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    status = await coordinator.get_mesh_status()
    return status


@app.get("/monitoring/metrics")
async def get_monitoring_metrics():
    """
    Get comprehensive monitoring metrics for the mesh network.

    Returns detailed information about:
    - Network health and performance
    - Active nodes and their status
    - Request volumes and latency
    - Token processing statistics
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    try:
        # Get mesh status
        mesh_status = await coordinator.get_mesh_status()

        # TODO: Query PostgreSQL for additional metrics
        # - Total requests over time
        # - Node performance statistics
        # - Cost and earnings data
        # - Historical latency data

        return {
            "mesh": mesh_status,
            "nodes": [],  # Will be populated from database
            "metrics": {
                "total_requests": 0,
                "avg_latency_ms": 0,
                "total_tokens_processed": 0,
                "network_health": 95.0
            },
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to fetch monitoring metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/monitoring/nodes")
async def get_active_nodes():
    """
    Get list of all active nodes in the mesh network with their metrics.

    Returns detailed per-node information including:
    - GPU specifications and utilization
    - Layers served and request counts
    - Earnings and uptime
    - Location and status
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    try:
        # TODO: Query PostgreSQL far_nodes table for node information
        # JOIN with far_session_contributions to get earnings data

        return {
            "nodes": [],  # Will be populated from database
            "total": 0,
            "active": 0,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to fetch node metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/inference/generate")
async def generate_inference(
    request: InferenceRequest,
    authorization: str = Header(None)
):
    """
    Generate text using distributed inference.

    This endpoint streams tokens back as they're generated by the mesh network.

    Returns:
        Server-Sent Events (SSE) stream with generated tokens
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    # TODO: Verify JWT token in authorization header
    # For now, we'll trust the user_wallet in the request

    logger.info(f"Inference request from {request.user_wallet[:10]}...")

    async def event_generator() -> AsyncIterator[str]:
        """Generate SSE events for streaming tokens"""
        try:
            async for token_response in coordinator.generate_streaming(request):
                # Format as Server-Sent Event
                data = token_response.model_dump_json()
                yield f"data: {data}\n\n"

            # Send completion event
            yield f"data: {json.dumps({'done': True})}\n\n"

        except Exception as e:
            logger.error(f"Inference error: {e}")
            error_data = json.dumps({
                "error": str(e),
                "request_id": request.request_id
            })
            yield f"data: {error_data}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@app.get("/models")
async def list_available_models():
    """
    List models available in the Far Mesh network.

    Returns information about which models are currently being served
    by GPU providers.
    """
    # TODO: Query discovery service for available models
    return {
        "models": [
            {
                "model_id": "meta-llama/Llama-2-7b-chat-hf",
                "active_nodes": 0,  # Will be populated from discovery service
                "price_per_token_far": "0.0001",
                "status": "available"
            }
        ]
    }


@app.post("/fine-tuning/start")
async def start_fine_tuning_job(
    request: FineTuningRequest,
    authorization: str = Header(None)
):
    """
    Start a distributed fine-tuning job.

    This endpoint initiates collaborative fine-tuning across the mesh network.
    Training is distributed across multiple GPU nodes with automatic gradient
    aggregation.

    Args:
        request: Fine-tuning job configuration
        authorization: JWT token for authentication

    Returns:
        Initial status of the fine-tuning job
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    # TODO: Verify JWT token in authorization header
    logger.info(f"Fine-tuning request from {request.user_wallet[:10]}...")

    try:
        status = await coordinator.start_fine_tuning(request)
        return status
    except RuntimeError as e:
        raise HTTPException(status_code=501, detail=str(e))
    except Exception as e:
        logger.error(f"Fine-tuning start error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/fine-tuning/status/{request_id}")
async def get_fine_tuning_job_status(
    request_id: str,
    authorization: str = Header(None)
):
    """
    Get status of a fine-tuning job.

    Returns current progress, loss, and cost information.
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    try:
        status = await coordinator.get_fine_tuning_status(request_id)
        return status
    except Exception as e:
        logger.error(f"Status check error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/fine-tuning/cancel/{request_id}")
async def cancel_fine_tuning_job(
    request_id: str,
    authorization: str = Header(None)
):
    """
    Cancel a running fine-tuning job.

    Stops training, saves checkpoint, and calculates final cost.
    """
    if not coordinator:
        raise HTTPException(status_code=503, detail="Coordinator not initialized")

    try:
        success = await coordinator.cancel_fine_tuning(request_id)
        return {"request_id": request_id, "canceled": success}
    except Exception as e:
        logger.error(f"Cancellation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "server:app",
        host="0.0.0.0",
        port=8100,
        reload=True,
        log_level="info"
    )
